# Water-Filled Potholes Detection

# Overview

Accidents resulting from poor road conditions and inadequate drainage systems are a common concern. During rainstorms, the visibility of potholes diminishes as the road surface becomes covered in water, posing significant risks to drivers and pedestrians. This often leads to accidents, traffic congestion, vehicle damage, and increased fuel consumption. Manual inspection methods and road assessments are available but lack real-time monitoring capabilities, precision, and actionable insights, requiring considerable effort, time, and financial resources.

To address these challenges, we present a framework that utilizes Convolutional Neural Networks (CNNs) to distinguish between normal road surfaces and water-filled potholes. Our model is trained using the YOLOv8 (You Only Look Once) algorithm, enabling accurate detection of potholes with high precision. This system aims to streamline road maintenance and repairs by facilitating the timely identification of water-filled potholes.

By leveraging advanced technologies such as image processing and deep learning, our framework automates the detection of water-filled potholes on roads. Through the utilization of YOLOv8, organizations can enhance their capability to detect water-filled potholes accurately and efficiently, thereby improving road safety and minimizing transportation disruptions.

## Features

- Detection of water-filled potholes in images or videos.
- Classification of potholes based on water presence.
- Integration with existing surveillance systems or vehicle-mounted cameras.
- Real-time or batch processing capabilities.
- Customizable threshold settings for detection accuracy.
- User-friendly interface for visualization and interaction.

## Collected Data images
   ![image](https://github.com/sushu-99/Waterfilled-Pothole-detection/assets/132267021/9f9655b9-bc17-4d5e-b4c0-30fd600197a1)
## Annoted Data images
   ![image](https://github.com/sushu-99/Waterfilled-Pothole-detection/assets/132267021/79623080-f3a7-4577-9ace-3c0e88766544)
## Accuracy on Bounding box

## Collected Data images



## Usage

The application provides both a command-line interface and a graphical user interface (GUI) for ease of use. Users can specify input images or videos for processing and adjust detection parameters as needed. Additionally, the system offers options for real-time processing if connected to a camera feed.



## Acknowledgments

Special thanks to the developers of OpenCV, TensorFlow, and other libraries used in this project. Article is ready to publish
